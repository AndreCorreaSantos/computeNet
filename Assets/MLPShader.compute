// Each #kernel tells which function to compile; you can have many kernels
#pragma kernel CSMain

// Create a RenderTexture with enableRandomWrite flag and set it
// with cs.SetTexture
RWTexture2D<float4> Result;

float activation(float sum, float steepness)
{
    return 1.0f / (1.0f + exp(-2.0f * steepness * sum));
}

//buffer to receive the weights
StructuredBuffer<float> Weights;
//buffer to receive the inputs
StructuredBuffer<float> Inputs;

//buffer to store the outputs
RWBuffer<float> Outputs;

struct Layer {
    int size; //number of neurons in the layer
    int nConnections; //number of connections to the next layer
};

StructuredBuffer<Layer> Layers;

//NEURONS is the max number of neurons in a given layer


groupshared float neurons[3]; // array to store the output of each neuron

int getPos(int layer, StructuredBuffer<Layer> layers){
    int pastConnections = 0;
    [unroll]
    for (int l =0; l < layer; l++){ //iterating over the layers
        pastConnections += layers[l].nConnections;
    }
    return pastConnections;
}

inline float getVal(uint pos, uint lSize, StructuredBuffer<float> Weights ) //adding all the inputs from the previous layer for a given neuron
{
    float val = 0.0f;
    for (uint n = 0; n < lSize; ++n, ++pos) //weight matrix is arranged in [connections to the first neuron from the last layer, connections to the second neuron from the last layer, ...]
    {
        val += Weights[pos] * neurons[n];
    }
    // val += weight[pos]; //neuron bias
    return val;
}

[numthreads(3,1,1)]
void CSMain (uint3 id : SV_DispatchThreadID)
{

    if (id.x < Layers[0].size) { // if thread is in the value range for the layer
        neurons[id.x] = Inputs[id.x]; //loading the input value into the neuron
    }

    float val = 0;
    uint pos;
    [unroll]// LAYERS is the number of hidden layers in the network 
    for (int l = 1; l <= 3; l++) { // for each neuron in the next layer this loop must run for all layers, so if the net has 3 layers (without the output) it must run from 1 to 3 
        int lsize = Layers[l].size;

        GroupMemoryBarrierWithGroupSync();
        int previousLsize = Layers[l-1].size;
        pos = getPos(l,Layers);
        val = getVal(pos,previousLsize,Weights);
        GroupMemoryBarrierWithGroupSync();

        neurons[id.x] = activation(val, 1.0f); // store the output of the neuron on the neuron array
    }

    if(id.x < 3){ // if thread is in the value range for the output layer ASSUMING THE OUTPUT LAYER HAS 3 NEURONS
        Outputs[id.x] = neurons[id.x]; // store the output of the neuron on the output array
    }
}
